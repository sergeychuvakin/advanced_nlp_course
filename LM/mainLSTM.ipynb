{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to run in colab\n",
    "\n",
    "# !git clone https://github.com/sergeychuvakin/advanced_nlp_course.git\n",
    "# !mv advanced_nlp_course/LM/*.py ./\n",
    "# !mv advanced_nlp_course/LM/*.json ./ ## \n",
    "# !pip install loguru pydantic tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "needed-aggregate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loguru==0.5.3\n",
      "nltk==3.6.2\n",
      "pydantic==1.8.2\n",
      "requests==2.25.1\n",
      "requests-oauthlib==1.3.0\n",
      "tokenizers==0.10.3\n",
      "torch==1.9.0\n",
      "torchtext==0.6.0\n",
      "tqdm==4.59.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | egrep \"pydantic|torch|loguru|tokenizers|requests|nltk|tqdm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "proof-preservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from loguru import logger\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "from dependencies import corpus, tokenizer\n",
    "from config import Config, LanguageModelConfig\n",
    "from processing_utils import (\n",
    "    clean_text, \n",
    "    split_on_sequences, \n",
    "    create_ngrams, \n",
    "    create_to_x_and_y, \n",
    "    word2int,\n",
    "    create_vocab,\n",
    "    save_artifacts\n",
    ")\n",
    "from model import LM_LSTM\n",
    "from datahandler import LMDataset\n",
    "from train_utils import train_model\n",
    "\n",
    "config = Config()\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"WARNING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-conviction",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = clean_text(corpus)\n",
    "corpus = split_on_sequences(corpus)\n",
    "\n",
    "tcorpus = tokenizer.encode_batch(corpus)\n",
    "\n",
    "## create n-grams for each doc\n",
    "sq = create_ngrams(tcorpus, config.N_GRAM) \n",
    " \n",
    "## shift corpus to create x and y \n",
    "x, y =  create_to_x_and_y(sq)\n",
    "\n",
    "id_token, token_id = create_vocab(tokenizer)\n",
    "vocab_size = len(token_id)\n",
    "\n",
    "## split data\n",
    "tradeoff_index = int(len(x) * config.TRAIN_PROPORTION)\n",
    "\n",
    "x_train = x[:tradeoff_index]\n",
    "x_test = x[tradeoff_index:]\n",
    "\n",
    "y_train = y[:tradeoff_index]\n",
    "y_test = y[tradeoff_index:]\n",
    "\n",
    "logger.warning(\n",
    "    f\"\"\"\n",
    "    Output shapes: \n",
    "        x_train: {len(x_train)}, \n",
    "        x_test: {len(x_test)}, \n",
    "        y_train: {len(y_train)}, \n",
    "        y_test: {len(y_test)}\n",
    "    \"\"\"\n",
    "              )\n",
    "\n",
    "## load to dataset and dataloader\n",
    "train_ds = LMDataset(x_train, y_train)\n",
    "test_ds = LMDataset(x_test, y_test)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# model and model config\n",
    "model_config = LanguageModelConfig(vocab_size=vocab_size, emb_size=300)\n",
    "model = LM_LSTM(**model_config.dict(), logger=logger)\n",
    "\n",
    "## save artifacts\n",
    "save_artifacts(\n",
    "    (model_config.dict(), config.SAVE_MODEL_CONFIG),\n",
    "    (token_id, config.SAVE_TOKEN_ID),\n",
    "    (id_token, config.SAVE_ID_TOKEN)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=model_config.lr)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# train model \n",
    "tmodel = train_model(model,\n",
    "                     train_dl,\n",
    "                     optimizer=optimizer,\n",
    "                     loss_func=loss_func,\n",
    "                     epochs=5, \n",
    "                     clip=1)\n",
    "\n",
    "torch.save(model.state_dict(), config.SAVE_MODEL_FNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-hostel",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "current-snapshot",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 16:01:24.897 | WARNING  | __main__:<module>:8 - \n",
      "    Cross-Entropy: 10.255110\n",
      "    Perpelxity: 28427.429688\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from validation_utils import val_metrics\n",
    "\n",
    "logger.warning(\n",
    "    \"\"\"\n",
    "    Cross-Entropy: %f\n",
    "    Perpelxity: %f\n",
    "    \"\"\" % \n",
    "    val_metrics(model, test_dl, token_id, loss_func)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-strand",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "neutral-verification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inference import (\n",
    "    model, \n",
    "    token_id, \n",
    "    id_token, \n",
    "    model, \n",
    "    predict_one_word, \n",
    "    predict_sample\n",
    ")\n",
    "\n",
    "from loguru import logger\n",
    "import sys\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"WARNING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "streaming-outdoors",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_one_word(\n",
    "    \"one of the\",  \n",
    "    model, \n",
    "    token_id, \n",
    "    id_token,\n",
    "    random=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "global-logic",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the , the . the the . , . the'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sample(\n",
    "    \"language modeling\",  \n",
    "    model, \n",
    "    token_id, \n",
    "    id_token,\n",
    "    length_of_sample=10,\n",
    "    random=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-scholar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
